Page,Block Index,Type,X1,Y1,X2,Y2,Text
1,1,Text,614.344970703125,732.0153198242188,1877.99951171875,773.5880737304688,"zejiang_shen, kaixuanzhang, melissadell}@fas.harvard.edu"
1,2,Text,1283.7938232421875,1825.0723876953125,2273.647216796875,2516.930419921875,"Complex layouts significantly complicate the automated
digitization of historical documents, which contain a variety
of rich information of interest to researchers and the pub-
lic more generally. In particular, many documents of rel-
evance to social science researchers and business analysts
contain complex, heterogeneous tabular and column struc-
tures, which off-the-shelf tools cannot recognize. More-
over, unique layout patterns appear in different languages.
For example, complex layouts with vertical text orienta-
tion are common in _ sian languages. Complex layouts dis-
rupt Optical Character Recognition (OCR) and result in text
from different columns, rows, or text regions being incor-
rectly garbled together, making automated digitization re-
sults unusable."
1,3,Text,202.94827270507812,1533.7672119140625,2264.01806640625,1673.052490234375,"Figure 1: Examples of HJDataset document images and annotations. (a) to (d) show images of the four page categories.
and (e) provides a simplified illustration of layout annotations for main pages. The seven types of hierarchically constructec
layout elements are highlighted in different colors."
1,4,Title,1288.5904541015625,1721.243896484375,1607.548828125,1777.3896484375,1. Introduction
1,5,Text,1279.3203125,2526.985107421875,2273.078857421875,2977.50732421875,"Various algorithms [2, 3] have been proposed to analyze
the layouts geometrically. They utilize visual properties like
text spacing and gaps to correct skewness and segment con-
tent regions with fine-tuned parameters. Recently, there has
been an increased interest in adopting deep learning (DL)
methods to build end-to-end layout understanding models.
For example, Oliveira et al. [16] and Xu et al. [23] build
models upon fully convolutional networks [13] to detect
page frames and text lines with high accuracy."
1,6,Text,196.6610565185547,1829.826904296875,1188.8369140625,2860.467041015625,"Deep learning-based approaches for automatic docu-
ment layout analysis and content extraction have the po-
tential to unlock rich information trapped in historical doc-
uments on a large scale. One major hurdle is the lack
of large datasets for training robust models. In particu-
lar, little training data exist for sian languages. To this
end, we present HJDataset, a Large Dataset of _ istorical
Japanese Documents with Complex Layouts. It contains
over 250,000 layout element annotations of seven types.
In addition to bounding boxes and masks of the con-
tent regions, it also includes the hierarchical structures
and reading orders for layout elements. The dataset is
constructed using a combination of human and machine
efforts. semi-rule based method is developed to ex-
tract the layout elements, and the results are checked by
human inspectors. The resulting large-scale dataset is
used to provide baseline performance analyses for text re-
gion detection using state-of-the-art deep learning mod-
els. nd we demonstrate the usefulness of the datasei
on real-world document digitization tasks. The dataset is
available at httpos://dell-research-harvarda."
1,7,Title,355.7864990234375,437.4557800292969,2226.9873046875,503.4242858886719,Large Dataset of Historical Japanese Documents with Complex Layouts
1,8,Title,641.4861450195312,1724.5797119140625,793.875244140625,1776.268310546875,bstract
1,9,Text,196.21018981933594,2825.986083984375,1176.69775390625,2917.597900390625,"available at https://dell-—research-harvard
github.io/HJ ataset/."
1,10,Text,273.49591064453125,1400.7080078125,495.40093994140625,1431.0784912109375,(a) Advertisement Page
1,11,Text,793.3726806640625,603.4689331054688,1643.4993896484375,715.0299682617188,"ejiang Shen Kaixuan Zhang Melissa I
Harvard University"
1,12,Text,749.8043212890625,606.8978881835938,1704.688720703125,663.6292724609375,Zejiang Shen Kaixuan Zhang Melissa Del
1,13,Title,369.9208068847656,434.2326965332031,2147.379638671875,696.2953491210938,"Large Dataset of Historical Japanese Documents with Complex Layou
Zejiang Shen Kaixuan Zhang Melissa Dell

Harvard TIlniverecty"
1,14,Text,761.0896606445312,604.0765380859375,1046.554931640625,658.4849243164062,Zejiang Shen
1,15,Text,71.44717407226562,1640.369384765625,138.33877563476562,2339.86328125,TAO8980 POOC:-ALXJe
1,16,Title,739.9129028320312,591.4154052734375,1784.343994140625,691.7684326171875,"Zejiang Shen Kaixuan Zhang Melissa Dell

LTarsard Tlrnixvarcitts"
1,17,Text,1455.615966796875,603.3142700195312,1711.025390625,657.337158203125,Melissa Dell
1,18,List,1280.2657470703125,2526.173095703125,2272.542724609375,2975.9765625,"Various algorithms [2, 3] have been proposed to analyze
the layouts geometrically. They utilize visual properties like
text spacing and gaps to correct skewness and segment con-
tent regions with fine-tuned parameters. Recently, there has
been an increased interest in adopting deep learning (DL)
methods to build end-to-end layout understanding models.
For example, Oliveira et al. [16] and Xu et al. [23] build
models upon fully convolutional networks [13] to detect
page frames and text lines with high accuracy."
1,19,Title,1316.9127197265625,1820.0911865234375,2280.331787109375,1867.677978515625,Complex layouts significantly complicate the automated
1,20,List,185.1431427001953,1778.3944091796875,1205.3975830078125,2916.403076171875,"Deep learning-based approaches for automatic docu-
ment layout analysis and content extraction have the po-
tential to unlock rich information trapped in historical doc-
uments on a large scale. One major hurdle is the lack
of large datasets for training robust models. In particu-
lar, little training data exist for sian languages. To this
end, we present HJDataset, a Large Dataset of _ istorical
Japanese Documents with Complex Layouts. It contains
over 250,000 layout element annotations of seven types.
In addition to bounding boxes and masks of the con-
tent regions, it also includes the hierarchical structures
and reading orders for layout elements. The dataset is
constructed using a combination of human and machine
efforts. semi-rule based method is developed to ex-
tract the layout elements, and the results are checked by
human inspectors. The resulting large-scale dataset is
used to provide baseline performance analyses for text re-
gion detection using state-of-the-art deep learning mod-
els. | nd we demonstrate the usefulness of the dataset
on real-world document digitization tasks. The dataset is
available at https://dell-research-harvard.
github.io/HJ ataset/."
2,1,Text,213.0833740234375,2320.700927734375,1193.148681640625,2714.011962890625,"Manual creation of such a dataset would be highly la-
porious, prohibitively costly, and potentially quite noisy.
Therefore, similar to PubLayNet [24], HJDataset is gener-
ated in a near-automatic fashion. With the help of a care-
fully designed semi-rule-based method, the layout elements
are accurately extracted. To ensure label quality, possible
2rrors are identified based on annotation statistics, and hu-
man inspectors correct some minor errors accordingly."
2,2,Text,209.95497131347656,321.73565673828125,1200.6851806640625,1007.312255859375,"Central lO the SUCCESS OF VL MOdeIs are Many labeled
samples for training and evaluating the neural networks.
There have been long term efforts to develop layout anal-
ysis datasets [1], and recently a very large-scale dataset has
been developed for modern documents [24]. However, for
historical documents, the existing datasets are small. For
example, there are only 150 instances in the DIV -HisDB
dataset [20] and 528 in the European Newspapers Project
Dataset [5]. Because deep neural nets tend to overfit small
datasets, models trained on them are less robust and perfor-
mance evaluation is less reliable. Because older documents
are subject to wearing, stains, and other noise that do not
appear in modern documents, they require dedicated large
datasets for training."
2,3,Text,208.20542907714844,1316.4075927734375,1203.1004638671875,2319.910400390625,"To attack these problems, we present the HJDataset:
a Large Dataset of Historical Japanese Documents with
Complex Layouts. Currently, this dataset contains 2,271
document image scans with various document informa-
tion, from the Japanese Who’s Who biographical direc-
tory published in 1953, which contains biographies for
around 50,000 prominent Japanese citizens [10]. For each
document image, HJDataset contains its content category
(main, index, advertisement, or other). For the
main and index pages, we create 25k layout region anno-
tations of seven types at different levels (from page frames
to individual text blocks). Besides the bounding box co-
ordinates, we also include the dependency structures and
reading orders for all the layout elements. The data are
stored in the COCO format [12], which is commonly used
in computer vision research. The resulting dataset provides
a ground truth for different document image analysis tasks,
from page classification to layout element detection. Exten-
sive experiments have been conducted, and state-of-the-art
models are trained and evaluated on this dataset."
2,4,Text,208.6385498046875,1013.60205078125,1201.0484619140625,1308.7080078125,"dditionally, most open-sourced historical document
layout datasets are in western languages [1, 5, 4]. Models
trained on them are not exposed to layout patterns that ap-
pear commonly and exclusively in sian languages. sian
language datasets will be required to build more generalized
layout analysis models."
2,5,Title,1282.0380859375,2690.953857421875,1758.5609130859375,2749.390380859375,3. Page Type Labeling
2,6,Text,1272.1959228515625,1578.6171875,2282.48681640625,2096.594482421875,"ee IIE EEE INE IIE) ISI IER
ing has revolutionized computer vision research, DL-based
document image analysis methods are also being developed
to tackle challenging tasks. [7] evaluates convolutional neu-
ral networks for document image classification tasks, and
[16] adapts the fully convolutional network (FCN) [13] to
detect layout element objects inside the page. For more
complicated tabular data, Schreiber et al. [19] adapt Faster
R-CNN [17] and FCN to identify their structures and parse
the contents. Behind their success, large datasets are re-
quired to train and evaluate the models."
2,7,Title,1286.26318359375,551.6553955078125,1641.1387939453125,605.6105346679688,2. Related Work
2,8,Text,1270.9344482421875,663.8402099609375,2272.627197265625,1480.8717041015625,"ae NT OE OOS NE NR BO NAN BLOAT ODO
datasets have been created in recent years [21]. For mod-
ern documents, ntonacopoulos et al.’s work [1] is the first
frequently-used dataset, with 305 images of magazines and
technical articles available for download. The recent Pub-
LayNet [24] dataset contains 360k samples from modern
research publications. For historical documents, the work
in [5] provides layout annotations for 600 historical Euro-
pean newspaper images. The datasets in [20] and [6] are
commonly used for medieval manuscripts and have 160 and
2036 samples respectively. Historical layout datasets tend
to be small and are largely unavailable for sian languages.
Large-scale digital libraries, such as the millions of scans
placed online by Japan’s National Diet Library, provide the
raw inputs for creating large datasets for historical docu-
ment layout analysis, but developing these datasets requires
methods that do not rely on costly human labeling."
2,9,Text,1281.450927734375,2779.009033203125,2273.18505859375,2981.15673828125,"Contents are organized very differently on pages of
different purposes, and hence the first step of the lay-
out analysis pipeline identifies the page type. We man-
ually labeled the page types according to their purposes."
2,10,Text,1297.8243408203125,2537.027099609375,2245.47998046875,2622.21044921875,"* -s COCO format does not contain an image-level category fielc

we add a new key for each image record called category id."
2,11,Table,1290.15576171875,2241.656494140625,2254.8388671875,2521.6962890625,"Page Type Number of images Category ID *
main 2048 8
advertisement 87 9
index 82 10
other 54 11"
2,12,Text,202.21029663085938,2723.9736328125,1194.238525390625,2939.5625,"The contribution of this work is twofold. First, we build
the HJDataset, the first large layout analysis dataset of his-
torical Japanese documents to the best of our knowledge.

semi-ruled-based method is designed for generating this"
2,13,Title,1285.7572021484375,1553.562255859375,1879.3818359375,1601.600341796875,Deep Learning for Layout na
2,14,Title,1281.5491943359375,640.4169921875,1739.879638671875,687.60498046875,Layout nalysis Dataset
2,15,Text,1309.8707275390625,2143.156982421875,2249.239501953125,2195.162109375,Table 1: Page types and numbers included in HJDataset
2,16,Text,1281.50341796875,307.2563781738281,2271.787841796875,507.0629577636719,"dataset can improve performance on other tasks with small
amounts of labeled data. The dataset and pre-trained mod-
els will be released online to support the development of
Japanese and more general layout analysis algorithms."
2,17,Title,1825.1658935546875,642.0840454101562,2270.580078125,687.6663208007812,variety of layout analysis
2,18,Text,203.34271240234375,2884.877197265625,1167.23681640625,2974.366943359375,"semi-ruled-based method 1s designed for generating th
dataset. Second, we show that models pre-trained on ot"
2,19,Title,1290.3463134765625,644.2283935546875,1416.714111328125,686.4425659179688,Layout
2,20,Title,2041.1556396484375,1553.906982421875,2266.747802734375,1600.1678466796875,; deep learn-
2,21,List,1283.102783203125,308.13836669921875,2281.89453125,506.23724365234375,"dataset can improve performance on other tasks with small
amounts of labeled data. The dataset and pre-trained mod-
els will be released online to support the development of
Japanese and more general layout analysis algorithms."
2,22,List,1268.2220458984375,1569.011962890625,2273.116943359375,2100.185302734375,"UICC Learns 10 LayOul MdlysiIs Ss GeCp ieadlii-
ing has revolutionized computer vision research, DL-based
document image analysis methods are also being developed
to tackle challenging tasks. [7] evaluates convolutional neu-
ral networks for document image classification tasks, and
[16] adapts the fully convolutional network (FCN) [13] to
detect layout element objects inside the page. For more
complicated tabular data, Schreiber et al. [19] adapt Faster
R-CNN [17] and FCN to identify their structures and parse
the contents. Behind their success, large datasets are re-
quired to train and evaluate the models."
2,23,List,1281.1884765625,630.7489624023438,2260.8603515625,1496.368408203125,"Layout nalysis Dataset variety of layout analysi:
datasets have been created in recent years [21]. For mod
ern documents, ntonacopoulos et al.’s work [1] is the firs
frequently-used dataset, with 305 images of magazines anc
technical articles available for download. The recent Pub
LayNet [24] dataset contains 360k samples from moder!
research publications. For historical documents, the worl
in [5] provides layout annotations for 600 historical Euro
pean newspaper images. The datasets in [20] and [6] ar
commonly used for medieval manuscripts and have 160 anc
2036 samples respectively. Historical layout datasets tenc
to be small and are largely unavailable for sian languages
Large-scale digital libraries, such as the millions of scan
placed online by Japan’s National Diet Library, provide thé
raw inputs for creating large datasets for historical docu
ment layout analysis, but developing these datasets require
methods that do not rely on costly human labeling."
3,1,Text,1280.0616455078125,2192.006591796875,2275.7861328125,2675.6474609375,"S lilustrated in Figure 5.a, we first estimate the page
frame box using contour detection. This method groups
pixels with similar visual properties like color or intensity
and can be used for extracting different regions [14]. In our
case, the largest intensity contour in the input delineates
the page boundary, and we estimate the four vertex coor-
dinates 2x y)}*_ of the circumscribed quadrilateral for
this contour as the page box. We convert the page image
inside the quadrilateral to a rectangle based on a warp affine
transformation."
3,2,Text,208.6825714111328,1931.3984375,1200.8009033203125,2437.432861328125,"s shown in Figure 2, the contents in the main pages are
organized in a hierarchical manner. Five rows are vertically
stacked in a page, while text region and title region are hor-
izontally arranged inside each row. The title region can be
further broken down into title and subtitle blocks, and other
irrelevant texts are labeled as the other type. The text region
blocks contain only vertical text lines and read from right to
left. Our objective is to segment the pages into units of sim-
ple layouts, namely, text region, title, and subtitle blocks.
Similar rules apply to the index pages."
3,3,Text,1286.629638671875,1636.812744140625,2278.2548828125,2188.810302734375,"The Text Block Detector extracts the content boxes in the
input scan in a hierarchical fashion. _ fter binarizing the
color scans, the recognition is conducted on different reso-
lutions to identify blocks of different scales. The algorithm
downsamples the image with a 1/8 ratio when detecting the
page frame and row boxes, while using the full resolutions
for extracting regions in each row. To account for possible
rotations and irregularities, we characterize the page frame
boxes with quadrilaterals. The row, text region, and title
region are represented with rectangles as the distortions are
largely eliminated within the page frames."
3,4,Text,211.7396240234375,2437.97998046875,1192.7222900390625,2977.0146484375,"Based on the hierarchical structures, we design a multi-
stage pipeline for robustly extracting the layout elements, il-
lustrated in Figure 3. For the input page scan, the Text Block
Detector first extracts the bounding boxes of page frame,
row, text region, and title region sequentially, as explained
in Section 4.1. | CNN is trained to predict the contextual
labels for the extracted regions, and the block segmentation
is refined accordingly (detailed in Section 4.2). _ fter that,
we construct the reading orders based on Japanese read-
ing rules, as described in Section 4.3. Finally, Section 4.4
discusses measures to identify and correct possible errors"
3,5,Title,1280.143310546875,1555.1761474609375,1760.7476806640625,1605.307861328125,4.1. Text Block Detector
3,6,Text,215.5384979248047,1444.528076171875,1197.7486572265625,1785.436767578125,"s shown in Figure |, four labels, le. main, index,
advertisement, and other, have been created for the
2k images. main pages present the detailed biographical
nformation of around 50,000 Japanese business, political,
and cultural leaders with complex structure, forming our
orimary focus. Table | provides a detailed description of the
classes and the number of samples contained in HJDataset."
3,7,Title,203.7740020751953,1839.2401123046875,899.41748046875,1892.591064453125,4. Document Layout nnotation
3,8,Text,1281.7200927734375,2680.625,2273.8232421875,2977.095458984375,"Connected Component Labeling (CCL) [18] and Run
Length Smoothing lgorithm (RLS) [15] are used for
splitting the five rows of contents vertically inside the page
frame. s weapply the RSL algorithm horizontally, each
row is connected, and CCL can be applied to differentiate
the rows. This approach is robust when the page is the end"
3,9,Text,1285.7725830078125,950.19287109375,2275.10498046875,1336.0218505859375,"rigure 5: Lhe four stages in layout element annotation.
Our method detects the coordinates of the page frames, row
regions, and text blocks. _ text block classifier is then used
to predict the block categories (indicated by the different
colors in the figure), and the detections are refined accord-
ingly. Reading orders and hierarchical dependency are gen-
erated for all layout elements. Finally human annotators
check the results and correct the errors."
3,10,Text,208.6201171875,957.2432250976562,1197.6488037109375,1342.4981689453125,"PIsure £4. AMC MiCrarCmiCar COMUCHE SUTUCTUTE Hi m if
pages. Each page contains five rows that are vertically
stacked, and the text regions are horizontally arranged
within each row. Texts are vertically written inside the text
region, e.g. (g) in the figure. The title region, e.g. (f), can
be further split into title and subtitle blocks. _n other cate-
gory is reserved for chapter headers and other irrelevant text
regions."
3,11,Text,1280.945068359375,1428.056884765625,2236.846435546875,1521.80322265625,"to ensure high quality of the generated annotations. T!
dataset statistics are provided in Section 4.5."
3,12,Title,285.290771484375,943.796875,1194.617431640625,989.29296875,re 2: The hierarchical content structure in m in
3,13,Title,1269.671630859375,1426.8016357421875,2272.613525390625,1524.3443603515625,"to ensure high quality of the generated annotations. The
dataset statistics are provided in Section 4.5."
3,14,Text,1307.470947265625,358.15496826171875,1749.748779296875,391.8342590332031,> Tg. Quality Control and Human Annotation
3,15,Title,1296.412353515625,944.4957275390625,2276.436279296875,989.3809204101562,igure 3: The four stages in layout element annotation.
3,16,List,1279.4139404296875,1426.6331787109375,2253.49560546875,1522.17724609375,"to ensure high quality of the generated annotations. Th
dataset statistics are provided in Section 4.5."
3,17,List,206.19723510742188,951.147216796875,1198.223388671875,1337.54833984375,"Figure 2: Lhe Merarchical content structure nm in
pages. Each page contains five rows that are vertically
stacked, and the text regions are horizontally arranged
within each row. Texts are vertically written inside the text
region, e.g. (g) in the figure. The title region, e.g. (f), can
be further split into title and subtitle blocks. _n other cate-
gory is reserved for chapter headers and other irrelevant text
regions."
3,18,List,1290.7454833984375,942.954833984375,2266.580078125,1379.8922119140625,"Figure 3: The four stages in layout element annotation.
Our method detects the coordinates of the page frames, row
regions, and text blocks. __ text block classifier is then used
to predict the block categories (indicated by the different
colors in the figure), and the detections are refined accord-
ingly. Reading orders and hierarchical dependency are gen-
erated for all layout elements. Finally human annotators
check the results and correct the errors."
3,19,Title,226.47125244140625,1438.28759765625,1192.498291015625,1487.141845703125,"s shown in Figure 1, four labels, i.e. main, index,"
3,20,List,1270.3580322265625,2674.786865234375,2267.169189453125,2980.18701171875,"Connected Component Labeling (CCL) [18] and Run
Length Smoothing lgorithm (RLS) [15] are used for
splitting the five rows of contents vertically inside the page
frame. s weapply the RSL algorithm horizontally, each
row is connected, and CCL can be applied to differentiate
the rows. This approach is robust when the page is the end"
3,21,Title,1312.3204345703125,1636.5360107421875,2270.772705078125,1681.4617919921875,The Text Block Detector extracts the content boxes in the
4,1,Text,203.2925262451172,2383.48583984375,1200.9822998046875,2975.3271484375,"We use the N SNet Mobile [25] architecture to build our
CNN. It is a neural network generated via Neural _ rchi-
tecture Search (N_ S) and achieves excellent performance
over many benchmarks. Our classifier is trained on 1,200
hand-labeled samples and tested on 100 samples. s mis-
segmentation rarely appears (only 3 in 1000 samples), we
re-balance the dataset distribution by manually creating 250
mis-segmented images. The input images are rescaled to the
same size of 200 height and 522 width. We train the model
from scratch, without loading pre-trained weights. Using a
stochastic gradient descent optimizer, the loss converges in
40 epochs with a final test accuracy of 0.99."
4,2,Text,205.47512817382812,1083.961669921875,1197.9599609375,1580.5828857421875,"of a chapter, where there could be fewer than five rows, and
the last row is not “full”. Similarly, for text and title regions
in arow, we apply RLS _ vertically and split the connected
components. Since the prediction is performed row-wise, it
is impossible to connect text blocks in different rows, and
the segmentation result is more robust. Rectangular bound-
ing box coordinates x y w h) are generated for each
row, text and title region, where x y ) is the coordinate
for the top-left corner, and w and h are width and height for
the rectangle, respectively."
4,3,Text,204.58180236816406,1979.4239501953125,1207.001953125,2364.91748046875,"three-class CNN classifier is trained to identify the
text, title, and wrongly-segmented regions. _ fter obtain-
ing the region bounding box from Text Region Detector, we
crop the page image based on the coordinates and predict its
category. If it is classified as mis-segmented, a CCL-based
method is applied to split it into text and title region. Title
regions are further broken down into more refined title and
subtitle segments, as illustrated in Figure 4."
4,4,Title,1277.66357421875,1931.9293212890625,2175.459716796875,1983.3446044921875,4.4. Quality Control and Human _nnotations
4,5,Text,1280.0162353515625,1155.3729248046875,2279.862060546875,1905.143310546875,"This publication contains non-trivial reading orders
which must also be deduced. The texts inside the basic ele-
ments (text region, title, and subtitle) are written vertically,
and read from right to left. dditionally, for text blocks in
a row, they also follow a right-to-left order. Black arrows in
Figure 4 shows the topological orders of different elements
in arow. However, some different structures also exist. s
indicated in Figure 5, section titles (shown in orange) dis-
rupt the regular right-to-left order of texts (see rows 2 and
3). s texts are usually densely arranged in each row, by
searching the large gaps between blocks, we identify the
discontinuity and correct the special reading order accord-
ingly. We incorporate this irregularity in the dataset to in-
clude the real-world noise and support the development of
more general layout understanding models."
4,6,Text,1270.597412109375,2017.68603515625,2273.753662109375,2312.612060546875,"Historical scans are challenging to analyze due to various
noise. Despite the carefully engineered method described
above, detection errors inevitably exist and need to be han-
dled carefully. However, considering the sheer number of
layout elements in this dataset, manual checking of all the
predictions would be highly laborious and potentially noisy."
4,7,Text,1273.2891845703125,2304.615234375,2272.04443359375,2804.507568359375,"To identify the small number of incorrect predictions
without searching the whole dataset, we examine statistics
about blocks and pages. _ s the main pages are densely
printed, we find the number of layout elements remains con-
sistent across pages, and blocks in a row are usually evenly
spaced. Hence, by filtering layout elements that are sig-
nificantly different in these statistics, we obtain a limited
number of misdetection candidates. _ s the specificity (true
negative rate) of the subsample is much higher, we can cor-
rect the problems more efficiently."
4,8,Title,201.9026641845703,1887.427978515625,1126.2188720703125,1939.8541259765625,4.2. Text Region Classification and Refinement
4,9,Title,1282.606201171875,1067.458740234375,1900.7156982421875,1121.178466796875,4.3. Reading Order Generation
4,10,Text,210.83335876464844,1589.786865234375,1188.275390625,1840.43212890625,"Text Block Detector finds the layout regions with high
accuracy (details in Section 4.4). However, text and title
regions are sometimes mis-segmented due to various noise
Hence, Text Region Classifier is developed to identify lay-
out categories and correct segmentation errors."
4,11,Text,211.0536346435547,880.6085205078125,1197.120849609375,976.59521484375,"Figure 4: Examples of the layout annotations and their
reading order."
4,12,Text,1280.2349853515625,2877.779052734375,2264.796875,2975.172607421875,"Misdetected Page Frames When a page is not appropri-
ately scanned, or it is physically broken, the page frame de-"
4,13,Text,1288.429443359375,883.49072265625,2276.763671875,977.7767333984375,"Figure 5: Irregular reading orders in the index pages.
The section header in row 2 and 3 disrupts the reading order."
4,14,Title,1280.7288818359375,2877.11181640625,2276.560302734375,2977.669189453125,"Misdetected Page Frames When a page is not appropri-
ately scanned, or it is physically broken, the page frame de-"
4,15,Text,1291.6082763671875,2082.44140625,2272.091796875,2633.314208984375,"PULLS. diropite tli Vaivitiy VMS tierirY ALICUTHUUE UL oOL LIVE
above, detection errors inevitably exist and need to be han-
dled carefully. However, considering the sheer number of
layout elements in this dataset, manual checking of all the
predictions would be highly laborious and potentially noisy.

To identify the small number of incorrect predictions
without searching the whole dataset, we examine statistics
about blocks and pages. _s the main pages are densely
printed, we find the number of layout elements remains con-
sistent across pages, and blocks in a row are usually evenly
spaced. Hence, by filtering layout elements that are sig-

rastanantix, Aiffarant in thaca atatictina ra nkhtoain +o limited"
4,16,List,1260.1923828125,2029.3778076171875,2266.533203125,2831.706298828125,"TLUSlULT dl sUdalls dll CHdAllela lis LO dildly Ze GUL LU VallUous
noise. Despite the carefully engineered method described
above, detection errors inevitably exist and need to be han-
dled carefully. However, considering the sheer number of
layout elements in this dataset, manual checking of all the
predictions would be highly laborious and potentially noisy.

To identify the small number of incorrect predictions
without searching the whole dataset, we examine statistics
about blocks and pages. _ s the main pages are densely
printed, we find the number of layout elements remains con-
sistent across pages, and blocks in a row are usually evenly
spaced. Hence, by filtering layout elements that are sig-
nificantly different in these statistics, we obtain a limited
number of misdetection candidates.  s the specificity (true
negative rate) of the subsample is much higher, we can cor-
rect the problems more efficiently."
4,17,Title,1287.6082763671875,881.6154174804688,2277.15283203125,974.7418212890625,"Figure 5: Irregular reading orders in the index pages.
The section header in row 2 and 3 disrupts the reading order."
4,18,Title,209.78726196289062,878.5265502929688,1198.34765625,977.345703125,"Figure 4: Examples of the layout annotations and their
reading order."
5,1,Text,1280.3250732421875,2472.380859375,2274.56201171875,2879.26904296875,"The three models are trained on all layout elements of
main pages from the training set. For fair comparison, they
are all being trained for 60k iterations, with a base 0.00025
learning rate, and a decay rate of 0.1 for each 30k itera-
tions. The batch size is 2, and the backbone CNN structure
is R-50-— PN-3x (details in [22]), loaded with pre-trained
weights from the COCO dataset. The training configuration
will also be open-sourced for reproduciblility."
5,2,Text,1275.9019775390625,1978.67529296875,2279.621337890625,2472.107177734375,"Without considering the dependency between contents,
layout analysis can be treated as detecting layout objects in-
side each page. _s object detection has been extensively
studied in current deep learning research, well-established
models like Faster R-CNN [17], RetinaNet [11], and Mask
R-CNN [8] have achieved excellent performance in various
benchmarks [12]. Hence, we adopt these models and train
them on our dataset. The implementation is based on Detec-
tron2 [22], and the neural networks are trained on a single
NVIDI RTX 2080Ti GPU."
5,3,Text,1283.2603759765625,2879.7880859375,2269.539794921875,2975.778076171875,"Table 3 shows the per-category bounding box prediction
mean verage Precision(m P) for intersection, at intersec-"
5,4,Text,211.71023559570312,1874.399169921875,1200.1085205078125,2268.20654296875,"aqiuonal Correcnion = rigure 6 SNOWS 1SSsues lke Cracks,
stains, and holes that appear frequently and can disrupt the
prediction pipeline. It is difficult to pre-screen all the mis-
segmentation and incorrect predictions due to these irreg-
ularities. Hence, during the manual checking process, hu-
man annotators are asked to identify such errors and correct
them. total of 111 layout elements have been found and
corrected so far."
5,5,Title,1286.560546875,1497.2664794921875,1610.7825927734375,1553.814453125,5. Experiments
5,6,Text,206.65574645996094,2266.559814453125,1196.369873046875,2603.645751953125,"In all, we fix more than 616 errors in total (since fix-
ing page frames leads to more improvements), and 80% are
identified by the statistical approach. We estimate that be-
fore correction, there are around 1,560 blocks detected in-
accurately.' _fter correcting the errors, the resultant dataset
achieves 99.6% accuracy, and the remaining 0.4% errors
can be neglected as random noise."
5,7,Text,1278.4932861328125,934.7120971679688,2268.025390625,1077.3604736328125,"examples of the annotations. Layout elements like text re-
gion and other do not appear in the index pages, as we
characterize the texts in index pages as title."
5,8,Text,1280.8709716796875,1096.9375,2271.586181640625,1430.78662109375,"We partition our dataset into training, validation, and
testing subsets: 70% for training and 15% each for vali-
dation and testing. The breakdown is stratified based on
the page type to ensure the equal exposure of different page
types in the three subsets. Because the characteristics of the
pages vary, categories appear in different frequencies, and
the dataset is unbalanced with respect to the object types."
5,9,Text,205.57147216796875,939.627197265625,1200.987548828125,1396.5458984375,"tection will become inaccurate, and it will disrupt the sub-
sequent extraction of row and text regions. _ large increase
or decrease in the number of layout elements in a page often
implies a misdetection of the page frame. Therefore, we se-
lect pages with more than 118 (95"" percentile) or less than
88 (5 percentile) layout elements and check them manu-
ally. This selects 182 pages, and 18 (9.9%) errors are identi-
fied. Their page frame coordinates are re-labeled manually.

fter correction, we re-run the pipeline over the pages in"
5,10,Title,208.53968811035156,2643.3271484375,897.6760864257812,2692.967041015625,4.5. Dataset Statistics and Partition
5,11,Text,1285.0599365234375,1589.243408203125,2265.36767578125,1837.0189208984375,"In this section, we first report results from training state-
of-the-art object detection models on the HJDataset. Perfor.
mance is evaluated and provided as a benchmark. Second
based on the pre-trained model, we study how HJDatase
can assist other layout analysis tasks."
5,12,Title,1280.26220703125,1885.10986328125,1902.27880859375,1934.7843017578125,5.1. Deep Learning Benchmark
5,13,Text,209.4479217529297,1510.5079345703125,1202.457275390625,1793.7960205078125,"ViIssed Lext Lines) ine last text nes in a text region are
sometimes missed if they contain only a few characters.
This results in unusually large gaps between text blocks.
This error can be easily identified by filtering the widths of
the block gaps. We select 1,011 blocks with gaps larger than
54 pixels (99"" percentile), and correct 487 of them."
5,14,Text,206.09524536132812,2857.41015625,1202.377197265625,2974.763916015625,"‘We randomly choose 20 pages, and count the error rate. This process
is repeated 3 times, and the average inaccuracy is 0.6%, which is equivalent
to 1,560 out of 260k blocks."
5,15,Text,213.62217712402344,1341.162109375,1175.406005859375,1428.67138671875,"Iter correction, we re-run the pipeline over the pages 1
order to detect other layout regions more accurately."
5,16,Text,1373.5963134765625,301.8227844238281,2189.39794921875,345.3836669921875,Table 2: Layout element categories and numbers
5,17,Table,1275.4052734375,387.94036865234375,2263.173095703125,899.8712158203125,"Category Training Validation Test Total
Page Frame 1490 320 320 2130
Row 7742 1657 1660 11059
Title Region | 33637 7184 7271 ~=48092
Text Region | 38034 8129 8207 = 54370
Title 66515 14931 14366 95812
Subtitle 33576 7173 7256 48005
Other 103 16 29 148
Total 181097 39410 39109 259616"
5,18,Title,333.19586181640625,742.4674072265625,1070.9766845703125,786.4754028320312,Figure 6: Various noises in the page scans.
5,19,Text,206.378173828125,2729.170166015625,1201.4742431640625,2817.618408203125,"total Of 259,610 layout elements of seven categories
have been extracted, as detailed in Table 2. Figure 7 shows"
5,20,Title,235.53070068359375,1863.9615478515625,1194.2535400390625,1909.54150390625,"dditional Correction Figure 6 shows issues like cracks,"
5,21,Title,211.26828002929688,2725.07470703125,1212.98583984375,2817.177734375,"total of 259,616 layout elements of seven categories
have been extracted, as detailed in Table 2. Figure 7 shows"
5,22,Title,213.59080505371094,1498.1756591796875,1201.366455078125,1545.7281494140625,Missed Text Lines The last text lines in a text region are
5,23,Title,238.75448608398438,1861.1639404296875,650.0973510742188,1907.670166015625,dditional Correction |
5,24,Title,204.80592346191406,1496.7154541015625,541.962646484375,1544.4932861328125,Missed Text Lines
5,25,List,211.66049194335938,2723.6083984375,1203.852783203125,2817.722412109375,"total of 259,616 layout elements of seven categories
have been extracted, as detailed in Table 2. Figure 7 shows"
5,26,List,191.91151428222656,2736.20947265625,1197.494384765625,2981.373046875,"tOldl OL 2I7,010 layout CICMeNts OL seven CalCSONes
have been extracted, as detailed in Table 2. Figure 7 shows

'We randomly choose 20 pages, and count the error rate. This process
is repeated 3 times, and the average inaccuracy is 0.6%, which is equivalent
to 1,560 out of 260k blocks."
5,27,Text,332.2875061035156,742.5662231445312,1065.1611328125,785.6290283203125,Figure 6: Various noises in the page scans.
5,28,List,206.47715759277344,931.5718994140625,1196.9337158203125,1428.747802734375,"tection will become inaccurate, and it will disrupt the sub-
sequent extraction of row and text regions. _ large increase
or decrease in the number of layout elements in a page often
implies a misdetection of the page frame. Therefore, we se-
lect pages with more than 118 (95"" percentile) or less than
88 (5 percentile) layout elements and check them manu-
ally. This selects 182 pages, and 18 (9.9%) errors are identi-
fied. Their page frame coordinates are re-labeled manually.

fter correction, we re-run the pipeline over the pages in
order to detect other layout regions more accurately."
5,29,Title,1373.3934326171875,297.133056640625,2191.554931640625,344.5757751464844,Table 2: Layout element categories and numbers
5,30,List,1276.7431640625,848.964111328125,2272.456787109375,1465.225830078125,"| LOLUA?L IATIVY JIFLUF 2I7FVIOD

examples of the annotations. Layout elements like text re-
gion and other do not appear in the index pages, as we
characterize the texts in index pages as title.

We partition our dataset into training, validation, and
testing subsets: 70% for training and 15% each for vali-
dation and testing. The breakdown is stratified based on
the page type to ensure the equal exposure of different page
types in the three subsets. Because the characteristics of the
pages vary, categories appear in different frequencies, and
the dataset is unbalanced with respect to the object types."
5,31,List,1290.45068359375,1856.27197265625,2271.550537109375,2498.284912109375,"5.1. Deep Learning Benchmark

Without considering the dependency between contents,
layout analysis can be treated as detecting layout objects in-
side each page. __s object detection has been extensively
studied in current deep learning research, well-established
models like Faster R-CNN [17], RetinaNet [11], and Mask
R-CNN [8] have achieved excellent performance in various
benchmarks [12]. Hence, we adopt these models and train
them on our dataset. The implementation is based on Detec-
tron2 [22], and the neural networks are trained on a single
NVIDI RTX 2080Ti GPU.

Tha thraan moadale ara trained nn all latunrnnt alamantec nf"
6,1,Text,1296.4478759765625,2836.554443359375,2264.066650390625,2956.5263671875,""" For training Mask R-CNN, the segmentation masks are the quadri-
lateral regions for each block. Compared to the rectangular bounding
boxes, they delineate the text region more accurately."
6,2,Text,210.08657836914062,2061.38134765625,1198.3369140625,2645.15380859375,"We also examine how our dataset can help with a real-
world document digitization application. When digitizing
new publications, researchers usually do not generate large
scale ground truth data to train their layout analysis models.
If they are able to adapt our dataset, or models trained on
our dataset, to develop models on their data, they can build
their pipelines more efficiently and develop more accurate
models. To this end, we conduct two experiments. First we
examine how layout analysis models trained on the main
pages can be used for understanding index pages. More-
over, we Study how the pre-trained models perform on other
historical Japanese documents."
6,3,Text,1286.2735595703125,1542.8748779296875,2269.134765625,2084.94677734375,"all the training data can be viewed as the benchmarks, while
training with few samples (five in this case) are consid-
ered to mimic real-world scenarios. Given different train-
ing data, models pre-trained on HJDataset perform signifi-
cantly better than those initialized with COCO weights. In-
tuitively, models trained on more data perform better than
those with fewer samples. We also directly use the model
trained on main to predict index pages without fine-
tuning. The low zero-shot prediction accuracy indicates the
dissimilarity between index and main pages. The large
increase in m P from 0.344 to 0.471 after the model is"
6,4,Text,212.82492065429688,1531.6424560546875,1191.268798828125,1933.0869140625,"tion over union (IOU) level [0.50:0.95]’, on the test data. In
general, the high m_ P values indicate accurate detection of
the layout elements. The Faster R-CNN and Mask R-CNN
achieve comparable results, better than RetinaNet. Notice-
ably, the detections for small blocks like title are less pre-
cise, and the accuracy drops sharply for the title category. In
Figure 8, (a) and (b) illustrate the accurate prediction results
of the Faster R-CNN model."
6,5,Text,208.9012451171875,2655.41845703125,1200.681640625,2857.654541015625,"Table 4 compares the performance of five Faster R-CNN
models that are trained differently on index pages. If the
model loads pre-trained weights from HJDataset, it includes
information learned from main pages. Models trained over"
6,6,Text,203.29330444335938,1349.5731201171875,2273.617919921875,1489.839599609375,"Figure 7: nnotation Examples in HJDataset. (a) and (b) show two examples for the labeling of main pages. The boxes
are colored differently to reflect the layout element categories. Illustrated in (c), the items in each index page row are
categorized as title blocks, and the annotations are denser."
6,7,Title,209.4040985107422,1972.1624755859375,887.429931640625,2021.3079833984375,5.2. Pre-training for other datasets
6,8,Text,217.09716796875,2897.852783203125,1196.2276611328125,2972.01318359375,"“This is a core metric developed for the COCO competition [12] for
-valuating the object detection quality."
6,9,Table,1278.474609375,2345.668212890625,2259.98193359375,2836.230712890625,"Category Faster R-CNN Mask R-CNN* RetinaNet
Page Frame 99.046 99.097 99.038
Row 98.831 98.482 95.067
Title Region 87.571 89.483 69.593
Text Region 94.463 86.798 89.531
Title 65.908 71.517 72.566
Subtitle 84.093 84.174 85.865
Other 44.023 39.849 14.371
m P 81.991 81.343 75.223"
6,10,Text,1278.1773681640625,2152.16162109375,2275.83642578125,2305.96142578125,"Table 3: Detection m P @ IOU [0.50:0.95] of different
models for each category on the test set. 11 values are given
as percentages."
6,11,Text,272.562255859375,1183.659423828125,750.2861938476562,1218.3658447265625,(a) Main Page Annotation Example 1
6,12,Title,1285.13427734375,2157.390380859375,2282.912841796875,2281.5849609375,"Table 3: Detection m P @ IOU [0.50:0.95] of different
models for each category on the test set. II values are given

AAO nrarnantanroacn"
6,13,Title,279.2358703613281,1181.9666748046875,746.4109497070312,1218.672119140625,(a) Main Page Annotation Example :
6,14,List,205.5258026123047,2044.009765625,1203.9595947265625,2751.89697265625,"We also examine how our dataset can help with a real-
world document digitization application. When digitizing
new publications, researchers usually do not generate large
scale ground truth data to train their layout analysis models.
If they are able to adapt our dataset, or models trained on
our dataset, to develop models on their data, they can build
their pipelines more efficiently and develop more accurate
models. To this end, we conduct two experiments. First we
examine how layout analysis models trained on the main
pages can be used for understanding index pages. More-
over, we study how the pre-trained models perform on other
historical Japanese documents.

Table 4 compares the performance of five Faster R-CNN
models that are trained differently on index pages. If the"
6,15,Text,208.33883666992188,1394.7376708984375,1605.1368408203125,1489.1103515625,"are colored differently to reflect the layout element categories. Illustrated in (c),
categorized as title blocks, and the annotations are denser."
7,1,Text,213.4566650390625,2234.548583984375,1187.3175048828125,2360.4072265625,"“Il indicates the model is trained on all 57 training index samples,

few-shot refers to model trained on 5 random samples, and zero-shot
means the model directly use the weights without training."
7,2,Text,190.40011596679688,1369.0152587890625,2269.54052734375,1656.649658203125,"Figure 6: Lhe prediction results of Faster K-CNN on Main pages In HJ Dataset and another publication. (a) shows that
the Faster R-CNN model is robust to noise like cracks and can detect most of the layout elements accurately. (b) highlights
some minor errors in the Faster R-CNN predictions like inaccurate row blocks, e.g. (1), and missed text and title regions, e.g.
(2) and (3). (c) shows the results of few-shot trained Faster R-CNN on another publication. They are generally correct. We
label the new publication differently to increase the difficulty for training, and the red boxes in the image denote a special
information region."
7,3,Title,1284.88134765625,2541.07373046875,1575.6181640625,2596.993408203125,6. Conclusion
7,4,Text,206.8334197998047,2682.01318359375,1198.8050537109375,2978.177978515625,"To evaluate our models on other historical Japanese doc-
uments, we manually annotate 12 pages from another pub-
lication with different layouts, the Japanese Whos Who bi-
ographical directory published in 1939 [9], and we train the
models on 4 samples. Performance is assessed on the re-
maining 8 samples, as reported in Table 5. Similar to the"
7,5,Text,196.61558532714844,1706.5645751953125,1195.991943359375,1855.6405029296875,"Table 4: Comparison of the test set P of Faster R-CNN
models trained differently on index pages. Il values are
given as percentages."
7,6,Text,1285.4580078125,2631.7548828125,2274.555419921875,2976.321044921875,"In this paper, we introduce the HJDataset, a large layout
analysis dataset for historical Japanese documents. With a
combination of semi-rule-based segmentation and statisti-
cal error identification and correction, 260k layout annota-
tions of seven categories are extracted from 2.2k page scans.
Page type labels, block dependency, and reading orders are
also included. Stored in COCO format, HJDataset allows"
7,7,Text,1280.01513671875,1707.8902587890625,2260.020263671875,1854.415283203125,"Table 5: Comparison of the test set P of Faster R-CND
models trained differently on another publication. II val
ues are given as percentages."
7,8,Text,207.12319946289062,2424.227783203125,1196.1412353515625,2676.656982421875,"trained on five samples shows that the model can be quickly
adapted to similar tasks. s the Ps 9 and P 5 ( P cal-
culated with IOU=0.50 and 0.75) are higher than m_ P, we
conclude that the models can learn to detect the general po-
sition of layout objects."
7,9,Text,1278.4759521484375,2201.05224609375,2270.386474609375,2495.264404296875,"previous experiment, pre-training on HJDataset has a large
positive influence on the detection accuracy given few train-
ing samples. nd shown in Figure 8 (c), the layout elements
are detected accurately. In summary, these two experiments
demonstrate the usefulness of our dataset for other layout
analysis tasks."
7,10,Table,214.56301879882812,1896.4730224609375,1185.238525390625,2217.69873046875,"Initialization | Training Data | m P Ps P35
COCO i 34.408 53.342 37.533
COCO Few-shot 9.988 18.572 9.669
HJDataset ll 47.125 67.502 54.410
HJDataset Few-shot 10.275 21.353 = 10.423
HJDataset Zero-shot 9.411 44.299 0.068"
7,11,Table,1273.814697265625,1892.4970703125,2266.541015625,2124.876220703125,"Initialization | Training Data | m P Ps P75

COCO Few-shot 69.925 95.119 78.667
HJDataset Few-shot 81.638 98.364 88.203
HJDataset Zero-shot 38.959 50.971 42.269"
7,12,Text,288.840087890625,1192.0142822265625,727.765380859375,1228.3873291015625,(a) Accurately Detected Main Pags
7,13,Title,221.37503051757812,1360.989013671875,2292.880859375,1408.7288818359375,‘igure 8: The prediction results of Faster R-CNN on Main pages in HJDataset and another publication. (a) shows that
7,14,Text,1668.808349609375,1179.3485107421875,2238.15576171875,1235.7789306640625,"(c) Detection Results on Another Publicatio1
with Few-shot Training"
7,15,Text,237.2631072998047,1363.1851806640625,2252.11474609375,1408.4468994140625,igure 8: The prediction results of Faster R-CNN on Main pages in HJDataset and another publication. (a) shows thé
7,16,Text,1806.800048828125,1288.1317138671875,2245.86181640625,1321.7508544921875,m Title Region Special Information Regio!
7,17,Title,292.7039489746094,1190.90380859375,725.0006713867188,1228.76904296875,(a) Accurately Detected Main Pag
7,18,Title,1921.318115234375,1288.8992919921875,2249.214599609375,1319.837158203125,»gion Special Information Regior
7,19,List,1267.152587890625,2200.890380859375,2277.215087890625,2490.520751953125,"previous experiment, pre-training on HJDataset has a large
positive influence on the detection accuracy given few train-
ing samples. nd shown in Figure 8 (c), the layout elements
are detected accurately. In summary, these two experiments
demonstrate the usefulness of our dataset for other layout
analysis tasks."
8,1,List,209.78016662597656,770.9888916015625,1196.6947021484375,2578.536865234375,"[1] postolos ntonacopoulos, David Bridson, Christos Pa-
padopoulos, and Stefan Pletschacher. realistic dataset for
performance evaluation of document layout analysis. In 2009
10th International Conference on Document nalysis and
Recognition, pages 296-300. IEEE, 2009.

[2] Thomas M Breuel. High performance document layout anal-
ysis. In Proceedings of the Symposium on Document Image
Understanding Technology, pages 209-218, 2003.

[3] Roldano Cattoni, Tarcisio Coianiz, Stefano Messelodi, and
Carla Maria Modena. Geometric layout analysis techniques
for document image understanding: a review. ITC-irst Tech-
nical Report, 9703(09), 1998.

[4] Christian Clausner, postolos ntonacopoulos, and Stefan
Pletschacher. ICD R2019 competition on recognition of
documents with complex layouts-rdcl2019. In 2019 Inter-
national Conference on Document nalysis and Recognition
(ICD _ R), pages 1521-1526. LEEE, 2019.

[5] Christian Clausner, Christos Papadopoulos, Stefan
Pletschacher, and postolos  ntonacopoulos. The ENP
image and ground truth dataset of historical newspapers. In
2015 13th International Conference on Document _ nalysis
and Recognition (ICD R), pages 931-935. IEEE, 2015.

[6] Tobias Griining, Roger Labahn, Markus Diem, Florian Kle-
ber, and Stefan Fiel. Read-bad: new dataset and evalua-
tion scheme for baseline detection in archival documents. In
2018 13thI PR International Workshop on Document _ nal-
ysis Systems (DS), pages 351-356. IEEE, 2018.

[7] dam W Harley, lex Ufkes, and Konstantinos G Derpanis.
Evaluation of deep convolutional nets for document image
classification and retrieval. In 2015 13th International Con-
ference on Document nalysis and Recognition (ICD R),
pages 991-995. IEEE, 2015.

[8] Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Gir-
shick. Mask R-CNN. In Proceedings of the [EEE inter-
national conference on computer vision, pages 2961-2969,
2017.

[9] Jinji Kshinjo. Jinji kshinroku, volume 11, 1939.

[10] Jinji Kshinjo. Jinji kshinroku, volume 17, 1953.

r4141m™_.... a ee ee ee ee |"
8,2,List,1283.5960693359375,341.1647644042969,2266.713623046875,3083.742919921875,"[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

baal baal

convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat:
tern recognition, pages 3431-3440, 2015.
Michael Randolph Maire. Contour detection and image seg-
mentation. Citeseer, 2009.
Nikos Nikolaou, Michael Makridis, Basilis Gatos, Niko-
laos Stamatopoulos, and Nikos Papamarkos. Segmentation
of historical machine-printed documents using adaptive run
length smoothing and skeleton segmentation paths. Image
and Vision Computing, 28(4):590-604, 2010.
Sofia res Oliveira, Benoit Seguin, and Frederic Kaplan.
dhSegment: generic deep-learning approach for document
segmentation. In 2018 16th International Conference or
Frontiers in Handwriting Recognition (ICFHR), pages 7-12.
IEEE, 2018.
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
Faster R-CNN: Towards real-time object detection with re-
gion proposal networks. In dvances in neural information
processing systems, pages 91-99, 2015.
Hanan Samet and Markku Tamminen. Efficient component
labeling of images of arbitrary dimension represented by lin-
ear bintrees. JEEE transactions on pattern analysis and ma-
chine intelligence, 10(4):579-586, 1988.
Sebastian Schreiber, Stefan gne, Ivo Wolf, ndreas Den-
gel, and Sheraz hmed. DeepDeSRT: Deep learning for de-
tection and structure recognition of tables in document im-
ages. In 2017 14th I PR International Conference on Doc-
ument nalysis and Recognition (ICD R), volume 1, pages
1162-1167. IEEE, 2017.
Foteini Simistira, Mathias Seuret, Nicole Eichenberger, _ n-
gelika Garz, Marcus Liwicki, and Rolf Ingold. Diva-hisdb:
precisely annotated large dataset of challenging medieval
manuscripts. In 20/6 I5th International Conference or
Frontiers in Handwriting Recognition (ICFHR), pages 471-
476. IEEE, 2016.
Ernest Valveny. Datasets and nnotations for Documen
nalysis and Recognition, pages 983-1009. Springer Lon-
don, London, 2014.
Yuxin Wu, lexander Kirillov, Francisco Massa, Wan- Yer
Lo, and Ross Girshick. Detectron2. https://github.
com/facebookresearch/detectron2, 2019.
Yue Xu, Fei Yin, Zhaoxiang Zhang, and Cheng-Lin Liu.
Multi-task layout analysis for historical handwritten docu-
ments using fully convolutional networks. In Proceedings oj
the Twenty-Seventh International Joint Conference on _ rtifi-
cial Intelligence, IJC I-18, pages 1057-1063. Internationa!
Joint Conferences on _ rtificial Intelligence Organization, 7
2018.
Xu Zhong, Jianbin Tang, and ntonio Jimeno Yepes. Pub-
laynet: largest dataset ever for document layout analysis.
arXiv preprint arXiv: 1908.07836, 2019.
Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V
Le. Learning transferable architectures for scalable image
recognition. In Proceedings of the IEEE conference or
computer vision and pattern recognition, pages 8697-8710.
2018."
8,3,List,228.42808532714844,2608.3251953125,1193.4833984375,2969.47314453125,"2]

Piotr Dollar. Focal loss for dense object detection. In Pro-
ceedings of the IEEE international conference on computer
vision, pages 2980-2988, 2017.

Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Dollér, and C Lawrence
Zitnick. Microsoft COCO: Common objects in context. In
European conference on computer vision, pages 740-755.
Springer, 2014."
8,4,Text,209.79290771484375,311.5842590332031,1192.8419189453125,506.5772399902344,"state-of-the-art object detection models to be easily trained
and evaluated. Moreover, we show that deep learning mod-
els trained on HJDataset can be adapted to other datasets,
facilitating real-world document digitization tasks."
8,5,Title,210.47669982910156,705.1012573242188,441.5044860839844,759.6038818359375,References
8,6,Text,224.892822265625,567.8997802734375,1188.6937255859375,659.6798095703125,"cknowledgement. This project is supported in part by
NSF Grant #1823616."
8,7,Text,1273.985595703125,310.2217102050781,2272.240478515625,446.5710144042969,"[13] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat-"
8,8,List,203.018310546875,1897.520751953125,1198.0841064453125,2970.314697265625,"[7]

[8]

[9]
[10]
[11]

[12]

tion scheme for baseline detection in archival documents. In
2018 13thI PR International Workshop on Document _ nal-
ysis Systems (DS), pages 351-356. IEEE, 2018.

dam W Harley, lex Ufkes, and Konstantinos G Derpanis.
Evaluation of deep convolutional nets for document image
classification and retrieval. In 2015 13th International Con-
ference on Document nalysis and Recognition (ICD R),
pages 991-995. IEEE, 2015.
Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Gir-
shick. Mask R-CNN. In Proceedings of the [EEE inter-
national conference on computer vision, pages 2961-2969,
2017.
Jinji Kshinjo. Jinji kshinroku, volume 11, 1939.
Jinji Kshinjo. Jinji kshinroku, volume 17, 1953.
Tsung- Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
Piotr Dollar. Focal loss for dense object detection. In Pro-
ceedings of the IEEE international conference on computer
vision, pages 2980-2988, 2017.
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Dollar, and C Lawrence
Zitnick. Microsoft COCO: Common objects in context. In
European conference on computer vision, pages 740-755.
Springer, 2014."
8,9,List,1283.552978515625,331.9866638183594,2271.229736328125,1538.812744140625,"Li~d

[14]

[15]

[16]

[17]

[18]

[19]

NDE ONDA OID BANDED AN BB NALIN ELL ODDIE OBNI BBN NE BANDEN RR RMD
convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat-
tern recognition, pages 3431-3440, 2015.

Michael Randolph Maire. Contour detection and image seg-
mentation. Citeseer, 2009.

Nikos Nikolaou, Michael Makridis, Basilis Gatos, Niko-
laos Stamatopoulos, and Nikos Papamarkos. Segmentation
of historical machine-printed documents using adaptive run
length smoothing and skeleton segmentation paths. Image
and Vision Computing, 28(4):590-604, 2010.

Sofia res Oliveira, Benoit Seguin, and Frederic Kaplan.
dhSegment: generic deep-learning approach for document
segmentation. In 2018 16th International Conference on
Frontiers in Handwriting Recognition (ICFHR), pages 7-12.
IEEE, 2018.

Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
Faster R-CNN: Towards real-time object detection with re-
gion proposal networks. In dvances in neural information
processing systems, pages 91-99, 2015.

Hanan Samet and Markku Tamminen. Efficient component
labeling of images of arbitrary dimension represented by lin-
ear bintrees. JEEE transactions on pattern analysis and ma-
chine intelligence, 10(4):579-586, 1988.

Sebastian Schreiber, Stefan gne, Ivo Wolf, ndreas Den-
gel, and Sheraz hmed. DeepDeSRT: Deep learning for de-

tantiann and ate ntien en nnnanitinn nf tahkhlan sn AHnanmar, t saan"
8,10,List,1270.346435546875,308.83172607421875,2277.18115234375,454.92974853515625,"{13] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat-"
8,11,Text,210.64031982421875,713.6333618164062,442.1932373046875,758.5556640625,References
8,12,Title,206.5009765625,564.3353271484375,1200.5125732421875,664.9230346679688,"cknowledgement. This project is supported in part by
NSF Grant #1823616."
8,13,Text,201.3617401123047,2458.806640625,1011.4622192382812,2599.7275390625,"[9] Jinji Kshinjo. Jinji kshinroku, volume 11, 1939.
({10] Jinji Kshinjo. Jinji kshinroku, volume 17, 1953.
[11] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kain"
8,14,List,1282.789794921875,1722.0955810546875,2268.85302734375,2964.388671875,"Low

[21]

[22]

[23]

[24]

[25]

EULCIIT OIIISUL A, IVEAUITAS OUULEL, LNINUIC LACMUMULI Eel, iim
gelika Garz, Marcus Liwicki, and Rolf Ingold. Diva-hisdb:
precisely annotated large dataset of challenging medieval
manuscripts. In 2016 15th International Conference on
Frontiers in Handwriting Recognition (ICFHR), pages 471-
476. IEEE, 2016.
Ernest Valveny. Datasets and nnotations for Document
nalysis and Recognition, pages 983-1009. Springer Lon-
don, London, 2014.
Yuxin Wu, lexander Kirillov, Francisco Massa, Wan-Yen
Lo, and Ross Girshick. Detectron2. https://github.
com/facebookresearch/detectron2, 2019.
Yue Xu, Fei Yin, Zhaoxiang Zhang, and Cheng-Lin Liu.
Multi-task layout analysis for historical handwritten docu-
ments using fully convolutional networks. In Proceedings oj
the Twenty-Seventh International Joint Conference on rtifi-
cial Intelligence, IJC I-18, pages 1057-1063. International
Joint Conferences on _ rtificial Intelligence Organization, 7
2018.
Xu Zhong, Jianbin Tang, and ntonio Jimeno Yepes. Pub-
laynet: largest dataset ever for document layout analysis.
arXiv preprint arXiv: 1908.07836, 2019.
Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V
Le. Learning transferable architectures for scalable image
recognition. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 8697-8710,
2018."
8,15,Text,205.67881774902344,616.5925903320312,566.0362548828125,662.8292236328125,NSF Grant #1823616
8,16,List,283.3423156738281,2554.167236328125,1190.3828125,2744.79736328125,"Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
Piotr Dollar. Focal loss for dense object detection. In Pro-
ceedings of the IEEE international conference on computei
vision, pages 2980-2988, 2017."
8,17,List,186.60858154296875,305.3343811035156,1158.046875,503.09490966796875,"state-of-the-art object detection models to be easily train
and evaluated. Moreover, we show that deep learning mo
els trained on HJDataset can be adapted to other datase
facilitating real-world document digitization tasks."
8,18,List,208.48016357421875,2452.529052734375,1014.3211669921875,2604.00146484375,"[9] Jinji Kshinjo. Jinji kshinroku, volume 11, 1939.
({10] Jinji Kshinjo. Jinji kshinroku, volume 17, 1953.
[11] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kain"
8,19,Text,354.2335510253906,2563.028564453125,1183.557861328125,2709.0234375,"1g- Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, anc
r Dollar. Focal loss for dense object detection. In Pro
lings of the IEEE international conference on compute"
8,20,Title,207.5912322998047,309.187255859375,1198.9659423828125,503.80743408203125,"state-of-the-art object detection models to be easily trained
and evaluated. Moreover, we show that deep learning mod-
els trained on HJDataset can be adapted to other datasets,
facilitating real-world document digitization tasks."
8,21,Text,229.34329223632812,2610.750244140625,1190.5704345703125,2976.69677734375,"2]

Piotr Dollar. Focal loss for dense object detection. In Pro-
ceedings of the IEEE international conference on computei
vision, pages 2980-2988, 2017.

Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays.
Pietro Perona, Deva Ramanan, Piotr Dollar, and C Lawrence
Zitnick. Microsoft COCO: Common objects in context. In
European conference on computer vision, pages 740-755.
Springer, 2014."
8,22,List,230.6997833251953,1711.5714111328125,1189.1790771484375,2500.7177734375,"[6]

[7]

[8]

[9]

2015 13th International Conference on Document _ nalysis
and Recognition (ICD R), pages 931-935. IEEE, 2015.
Tobias Griining, Roger Labahn, Markus Diem, Florian Kle-
ber, and Stefan Fiel. Read-bad: new dataset and evalua-
tion scheme for baseline detection in archival documents. In
2018 13thI PR International Workshop on Document _ nal-
ysis Systems (DS), pages 351-356. IEEE, 2018.

dam W Harley, lex Ufkes, and Konstantinos G Derpanis.
Evaluation of deep convolutional nets for document image
classification and retrieval. In 2015 13th International Con-
ference on Document nalysis and Recognition (ICD R).
pages 991-995. IEEE, 2015.
Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Gir-
shick. Mask R-CNN. In Proceedings of the [EEE inter-
national conference on computer vision, pages 2961-2969.
2017.
Jinji Kshinjo. Jinji kshinroku, volume 11, 1939."
